{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AWH-Geo",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AWH-GlobalPotential-X/AWH-Geo/blob/master/notebooks/AWH-Geo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WVlEskqN7cz"
      },
      "source": [
        "Welcome to AWH-Geo\n",
        "\n",
        "This tool requires a [Google Drive](https://drive.google.com/drive/my-drive) and [Earth Engine](https://developers.google.com/earth-engine/) Account.\n",
        "\n",
        "[Start here](https://drive.google.com/drive/u/1/folders/1EzuqsbADrtdXChcpHqygTh7SuUw0U_QB) to create a new Output Table from the template:\n",
        " 1. Right-click on \"OutputTable_TEMPLATE\" file > Make a Copy to your own Drive folder\n",
        " 2. Rename the new file \"OuputTable_CODENAME\" with CODENAME (max 83 characters!) as a unique output table code. If including a date in the code, use the YYYYMMDD date format.\n",
        " 3. Enter in the output values in L/hr to each cell in each of the 10%-interval rH bins... interpolate in Sheets as necessary.\n",
        "\n",
        "Then, click \"Connect\" at the top right of this notebook.\n",
        "\n",
        "Then run each of the code blocks below, following instructions. For \"OutputTableCode\" inputs, use the CODENAME you created in Sheets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stHr1at7Vz4j",
        "cellView": "form"
      },
      "source": [
        "#@title Basic setup and earthengine access.\n",
        "\n",
        "print('Welcome to AWH-Geo')\n",
        "\n",
        "# import, authenticate, then initialize EarthEngine module ee\n",
        "# https://developers.google.com/earth-engine/python_install#package-import\n",
        "import ee \n",
        "print('Make sure the EE version is v0.1.215 or greater...')\n",
        "print('Current EE version = v' + ee.__version__)\n",
        "print('')\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "worldGeo = ee.Geometry.Polygon( # Created for some masking and geo calcs\n",
        "  coords=[[-180,-90],[-180,0],[-180,90],[-30,90],[90,90],[180,90],\n",
        "          [180,0],[180,-90],[30,-90],[-90,-90],[-180,-90]],\n",
        "  geodesic=False,\n",
        "  proj='EPSG:4326'\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdm_p_0kXJ4k",
        "cellView": "form"
      },
      "source": [
        "#@title Test Earth Engine connection (see Mt Everest elev and a green map)\n",
        "# Print the elevation of Mount Everest.\n",
        "dem = ee.Image('USGS/SRTMGL1_003')\n",
        "xy = ee.Geometry.Point([86.9250, 27.9881])\n",
        "elev = dem.sample(xy, 30).first().get('elevation').getInfo()\n",
        "print('Mount Everest elevation (m):', elev)\n",
        "\n",
        "# Access study assets\n",
        "from IPython.display import Image\n",
        "jmpGeofabric_image = ee.Image('users/awhgeoglobal/jmpGeofabric_image') # access to study folder in EE\n",
        "Image(url=jmpGeofabric_image.getThumbUrl({'min': 0, 'max': 1, 'dimensions': 512,\n",
        "                'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HExr-p1zf2zm",
        "cellView": "form"
      },
      "source": [
        "#@title Set up access to Google Sheets (follow instructions)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# gspread is module to access Google Sheets through python\n",
        "# https://gspread.readthedocs.io/en/latest/index.html\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default()) # get credentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k6X9TzPg3gl",
        "cellView": "form"
      },
      "source": [
        "#@title STEP 1: Export timeseries for given OutputTable: enter CODENAME (without \"OutputTable_\" prefix) below\n",
        "\n",
        "OutputTableCode = \"\" #@param {type:\"string\"}\n",
        "StartYear = 2010 #@param {type:\"integer\"}\n",
        "EndYear = 2020 #@param {type:\"integer\"}\n",
        "ExportWeekly_1_or_0 =   0#@param {type:\"integer\"}\n",
        "\n",
        "ee_username = ee.String(ee.Dictionary(ee.List(ee.data.getAssetRoots()).get(0)).get('id'))\n",
        "ee_username = ee_username.getInfo()\n",
        "\n",
        "years = list(range(StartYear,EndYear))\n",
        "print('Time Period: ', years)\n",
        "\n",
        "def timeseriesExport(outputTable_code):\n",
        "  \n",
        "  \"\"\"\n",
        "  This script runs the output table value over the climate variables using the \n",
        "  nearest lookup values, worldwide, every three hours during a user-determined \n",
        "  period. It then resamples the temporal interval by averaging the hourly output \n",
        "  over semi-week periods. It then converts the resulting image collection into a \n",
        "  single image with several bands, each of which representing one (hourly or \n",
        "  semi-week) interval. Finally, it exports this image over 3-month tranches and \n",
        "  saves each as an EE Image Assets with appropriate names corresponding to the \n",
        "  tranche's time period. \n",
        "  \"\"\"\n",
        "  \n",
        "  # print the output table code from user input for confirmation\n",
        "  print('outputTable code:', outputTable_code)\n",
        "\n",
        "  # CLIMATE DATA PRE-PROCESSING\n",
        "  # ERA5-Land climate dataset used for worldwide (derived) climate metrics\n",
        "  # https://www.ecmwf.int/en/era5-land\n",
        "  # era5-land HOURLY images in EE catalog\n",
        "  era5Land = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \n",
        "  # print('era5Land',era5Land.limit(50)) # print some data for inspection (debug)\n",
        "  era5Land_proj = era5Land.first().projection() # get ERA5-Land projection & scale for export\n",
        "  era5Land_scale = era5Land_proj.nominalScale()\n",
        "  print('era5Land_scale (should be ~11132):',era5Land_scale.getInfo())\n",
        "  era5Land_filtered = era5Land.filterDate( # ERA5-Land climate data\n",
        "    str(StartYear-1) + '-12-31', str(EndYear) + '-01-01').select( # filter by date\n",
        "        # filter by ERA5-Land image collection bands                              \n",
        "        [\n",
        "         'dewpoint_temperature_2m', # K (https://apps.ecmwf.int/codes/grib/param-db?id=168)\n",
        "         'surface_solar_radiation_downwards', # J/m^2 (Accumulated value. Divide by 3600 to get W/m^2 over hourly interval https://apps.ecmwf.int/codes/grib/param-db?id=176)\n",
        "         'temperature_2m' # K\n",
        "         ]) \n",
        "  # print('era5Land_filtered',era5Land_filtered.limit(50))\n",
        "\n",
        "  print('Wait... retrieving data from sheets takes a couple minutes')\n",
        "\n",
        "  # COLLECT OUTPUT TABLE DATA FROM SHEETS INTO PYTHON ARRAYS\n",
        "  # gspread function which will look in list of gSheets accessible to user\n",
        "  # in Earth Engine, an array is a list of lists.\n",
        "  # loop through worksheet tabs and build a list of lists of lists (3 dimensional)\n",
        "  # to organize output values [L/hr] by the 3 physical variables in the following\n",
        "  # order: by temperature (first nesting leve), ghi (second nesting level), then\n",
        "  # rH (third nesting level).\n",
        "  spreadsheet = gc.open('OutputTable_' + outputTable_code) \n",
        "  outputArray = list() # create empty array\n",
        "  rH_labels = ['rH0','rH10','rH20','rH30','rH40','rH50', # worksheet tab names\n",
        "               'rH60','rH70','rH80','rH90','rH100']\n",
        "  for rH in rH_labels: # loop to create 3-D array (list of lists of lists)\n",
        "    rH_interval_array = list() \n",
        "    worksheet = spreadsheet.worksheet(rH)\n",
        "    for x in list(range(7,26)): # relevant ranges in output table sheet\n",
        "      rH_interval_array.append([float(y) for y in worksheet.row_values(x)])\n",
        "    outputArray.append(rH_interval_array)\n",
        "  # print('Output Table values:', outputArray) # for debugging\n",
        "  # create an array image in EE (each pixel is a multi-dimensional matrix)\n",
        "  outputImage_arrays = ee.Image(ee.Array(outputArray)) # values are in [L/hr]\n",
        "\n",
        "  def processTimeseries(i): # core processing algorithm with lookups to outputTable\n",
        "\n",
        "    \"\"\"\n",
        "    This is the core AWH-Geo algorithm to convert image-based input climate data \n",
        "    into an image of AWG device output [L/time] based on a given output lookup table.\n",
        "    It runs across the ERA5-Land image collection timeseries and runs the lookup table \n",
        "    on each pixel of each image representing each hourly climate timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    i = ee.Image(i) # cast as image\n",
        "    i = i.updateMask(i.select('temperature_2m').mask()) # ensure mask is applied to all bands\n",
        "    timestamp_millis = ee.Date(i.get('system:time_start'))\n",
        "    i_previous = ee.Image(era5Land_filtered.filterDate(\n",
        "        timestamp_millis.advance(-1,'hour')).first())\n",
        "    rh = ee.Image().expression( # relative humidity calculation [%]\n",
        "    # from http://bmcnoldy.rsmas.miami.edu/Humidity.html\n",
        "      '100 * (e**((17.625 * Td) / (To + Td)) / e**((17.625 * T) / (To + T)))', {\n",
        "        'e': 2.718281828459045, # Euler's constant\n",
        "        'T': i.select('temperature_2m').subtract(273.15), # temperature K converted to Celsius [째C]\n",
        "        'Td': i.select('dewpoint_temperature_2m').subtract(273.15), # dewpoint temperature K converted to Celsius [째C]\n",
        "        'To': 243.04 # reference temperature [K]\n",
        "      }).rename('rh')\n",
        "    ghi = ee.Image(ee.Algorithms.If( # because this parameter in ERA5 is cumulative in J/m^2...\n",
        "        condition=ee.Number(timestamp_millis.get('hour')).eq(1), # ...from last obseration...\n",
        "        trueCase=i.select('surface_solar_radiation_downwards'), # ...current value must be...\n",
        "        falseCase=i.select('surface_solar_radiation_downwards').subtract( # ...subtracted from last...\n",
        "            i_previous.select('surface_solar_radiation_downwards')) # ... then divided by seconds\n",
        "      )).divide(3600).rename('ghi') # solar global horizontal irradiance [W/m^2]\n",
        "    temp = i.select('temperature_2m'\n",
        "                    ).subtract(273.15).rename('temp') # temperature K converted to Celsius [째C]\n",
        "    rhClamp = rh.clamp(0.1,100) # relative humdity clamped to output table range [%]\n",
        "    ghiClamp = ghi.clamp(0.1,1300) # global horizontal irradiance clamped to range [W/m^2]\n",
        "    tempClamp = temp.clamp(0.1,45) # temperature clamped to output table range [째C]\n",
        "    # convert climate variables to lookup integers\n",
        "    rhLookup = rhClamp.divide(10\n",
        "                    ).round().int().rename('rhLookup') # rH lookup interval\n",
        "    tempLookup = tempClamp.divide(2.5\n",
        "                    ).round().int().rename('tempLookup') # temp lookup interval\n",
        "    ghiLookup = ghiClamp.divide(100\n",
        "                    ).add(1).round().int().rename('ghiLookup') # ghi lookup interval\n",
        "    # combine lookup values in a 3-band image\n",
        "    xyzLookup = ee.Image(rhLookup).addBands(tempLookup).addBands(ghiLookup) \n",
        "    # lookup values in 3D array for each pixel to return AWG output from table [L/hr]\n",
        "    # set output to 0 if temperature is less than 0 deg C\n",
        "    output = outputImage_arrays.arrayGet(xyzLookup).multiply(temp.gt(0))\n",
        "    nightMask = ghi.gt(0.5) # mask pixels which have no incident sunlight\n",
        "\n",
        "    return ee.Image(output.rename('O').addBands( # return image of output labeled \"O\" [L/hr]\n",
        "      rh.updateMask(nightMask)).addBands(\n",
        "          ghi.updateMask(nightMask)).addBands(\n",
        "              temp.updateMask(nightMask)).setMulti({ # add physical variables as bands\n",
        "        'system:time_start': timestamp_millis # set time as property\n",
        "      })).updateMask(1) # close partial masks at continental edges\n",
        "\n",
        "  def outputHourly_export(timeStart, timeEnd, year):\n",
        "\n",
        "    \"\"\"\n",
        "    Run the lookup processing function (from above) across the entire climate \n",
        "    timeseries at the finest temporal interval (1 hr for ERA5-Land). Convert the \n",
        "    resulting image collection as a single image with a band for each timestep \n",
        "    to allow for export as an Earth Engine asset (you cannot export/save image\n",
        "    collections as assets).\n",
        "    \"\"\"\n",
        "\n",
        "    # filter ERA5-Land climate data by time\n",
        "    era5Land_filtered_section = era5Land_filtered.filterDate(timeStart, timeEnd)\n",
        "\n",
        "    # print('era5Land_filtered_section',era5Land_filtered_section.limit(1).getInfo())\n",
        "\n",
        "    outputHourly = era5Land_filtered_section.map(processTimeseries) \n",
        "    # outputHourly_toBands_pre = outputHourly.select(['ghi']).toBands()\n",
        "    outputHourly_toBands_pre = outputHourly.select(['O']).toBands()\n",
        "    outputHourly_toBands = outputHourly_toBands_pre.select(\n",
        "      # input climate variables as multiband image with each band representing timestep\n",
        "      outputHourly_toBands_pre.bandNames(), \n",
        "      # rename bands by timestamp\n",
        "      outputHourly_toBands_pre.bandNames().map(\n",
        "        lambda name: ee.String('H').cat( # \"H\" for hourly\n",
        "          ee.String(name).replace('T','')\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "\n",
        "    # notify user of export\n",
        "    print('Exporting outputHourly year:', year)\n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "      image=ee.Image(outputHourly_toBands),\n",
        "      region=worldGeo,\n",
        "      description='O_hourly_' + outputTable_code + '_' + year,\n",
        "      assetId=ee_username + '/O_hourly_' + outputTable_code + '_' + year,\n",
        "      scale=era5Land_scale.getInfo(),\n",
        "      maxPixels=1e10,\n",
        "      maxWorkers=2000\n",
        "    )\n",
        "    task.start()\n",
        "  \n",
        "  # run timeseries export on entire hourly ERA5-Land for each yearly tranche\n",
        "\n",
        "  for y in years:\n",
        "    y = str(y)\n",
        "    outputHourly_export(y + '-01-01', y + '-04-01', y + 'a')\n",
        "    outputHourly_export(y + '-04-01', y + '-07-01', y + 'b')\n",
        "    outputHourly_export(y + '-07-01', y + '-10-01', y + 'c')\n",
        "    outputHourly_export(y + '-10-01', str(int(y)+1) + '-01-01', y + 'd')\n",
        "\n",
        "  def outputWeekly_export(timeStart, timeEnd, year):\n",
        "\n",
        "    era5Land_filtered_section = era5Land_filtered.filterDate(timeStart, timeEnd) # filter ERA5-Land climate data by time\n",
        "    \n",
        "    outputHourly = era5Land_filtered_section.map(processTimeseries)\n",
        "    \n",
        "    # resample values over time by 2-week aggregations\n",
        "    # Define a time interval\n",
        "    start = ee.Date(timeStart)\n",
        "    end = ee.Date(timeEnd)\n",
        "    # Number of years, in DAYS_PER_RANGE-day increments.\n",
        "    DAYS_PER_RANGE = 14\n",
        "    # DateRangeCollection, which contains the ranges we're interested in.\n",
        "    drc = ee.call(\"BetterDateRangeCollection\",\n",
        "      start,\n",
        "      end, \n",
        "      DAYS_PER_RANGE, \n",
        "      \"day\",\n",
        "      True)\n",
        "    # This filter will join images with the date range that contains their start time.\n",
        "    filter = ee.Filter.dateRangeContains(\"date_range\", None, \"system:time_start\")\n",
        "    # Save all of the matching values under \"matches\".\n",
        "    join = ee.Join.saveAll(\"matches\")\n",
        "    # Do the join.\n",
        "    joinedResult = join.apply(drc, outputHourly, filter)\n",
        "    # print('joinedResult',joinedResult)\n",
        "    \n",
        "    # Map over the functions, and add the mean of the matches as \"meanForRange\".\n",
        "    joinedResult = joinedResult.map(\n",
        "      lambda e: e.set(\"meanForRange\", ee.ImageCollection.fromImages(e.get(\"matches\")).mean())\n",
        "    )\n",
        "    # print('joinedResult',joinedResult)\n",
        "\n",
        "    # roll resampled images into new image collection\n",
        "    outputWeekly = ee.ImageCollection(joinedResult.map(\n",
        "        lambda f: ee.Image(f.get('meanForRange'))\n",
        "    ))\n",
        "    # print('outputWeekly',outputWeekly.getInfo())\n",
        "\n",
        "    # convert image collection into image with many bands which can be saved as EE asset\n",
        "    outputWeekly_toBands_pre = outputWeekly.toBands()\n",
        "    outputWeekly_toBands = outputWeekly_toBands_pre.select(\n",
        "        outputWeekly_toBands_pre.bandNames(), # input climate variables as multiband image with each band representing timestep\n",
        "        outputWeekly_toBands_pre.bandNames().map(\n",
        "            lambda name: ee.String('W').cat(name)\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "      image=ee.Image(outputWeekly_toBands),\n",
        "      region=worldGeo,\n",
        "      description='O_weekly_' + outputTable_code + '_' + year,\n",
        "      assetId=ee_username + '/O_weekly_' + outputTable_code + '_' + year,\n",
        "      scale=era5Land_scale.getInfo(),\n",
        "      maxPixels=1e10,\n",
        "      maxWorkers=2000\n",
        "    )\n",
        "    if ExportWeekly_1_or_0 == 1:\n",
        "      task.start() # remove comment hash if weekly exports are desired\n",
        "      print('Exporting outputWeekly year:', year)\n",
        "\n",
        "  # run semi-weekly timeseries export on ERA5-Land by year\n",
        "  for y in years:\n",
        "    y = str(y)\n",
        "    outputWeekly_export(y + '-01-01', y + '-04-01', y + 'a')\n",
        "    outputWeekly_export(y + '-04-01', y + '-07-01', y + 'b')\n",
        "    outputWeekly_export(y + '-07-01', y + '-10-01', y + 'c')\n",
        "    outputWeekly_export(y + '-10-01', str(int(y)+1) + '-01-01', y + 'd')\n",
        "\n",
        "timeseriesExport(OutputTableCode)\n",
        "\n",
        "print('Complete! Read instructions below')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7G6VUdE1g5e"
      },
      "source": [
        "# *Before moving on to the next step... Wait until above tasks are complete in the task manager: https://code.earthengine.google.com/*\n",
        "(right pane, tab \"tasks\", click \"refresh\"; the should show up once the script prints \"Exporting...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptJRgoHbicHa",
        "cellView": "form"
      },
      "source": [
        "#@title Re-instate earthengine access (follow instructions)\n",
        "\n",
        "print('Welcome Back to AWH-Geo')\n",
        "print('')\n",
        "\n",
        "# import, authenticate, then initialize EarthEngine module ee\n",
        "# https://developers.google.com/earth-engine/python_install#package-import\n",
        "import ee \n",
        "print('Make sure the EE version is v0.1.215 or greater...')\n",
        "print('Current EE version = v' + ee.__version__)\n",
        "print('')\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "worldGeo = ee.Geometry.Polygon( # Created for some masking and geo calcs\n",
        "  coords=[[-180,-90],[-180,0],[-180,90],[-30,90],[90,90],[180,90],\n",
        "          [180,0],[180,-90],[30,-90],[-90,-90],[-180,-90]],\n",
        "  geodesic=False,\n",
        "  proj='EPSG:4326'\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfApoE9rtB9n",
        "cellView": "form"
      },
      "source": [
        "#@title STEP 2: Export statistical results for given OutputTable: enter CODENAME (without \"OutputTable_\" prefix) below\n",
        "\n",
        "ee_username = ee.String(ee.Dictionary(ee.List(ee.data.getAssetRoots()).get(0)).get('id'))\n",
        "ee_username = ee_username.getInfo()\n",
        "\n",
        "OutputTableCode = \"\" #@param {type:\"string\"}\n",
        "StartYear = 2010 #@param {type:\"integer\"}\n",
        "EndYear =  2020 #@param {type:\"integer\"}\n",
        "SuffixName_optional = \"\" #@param {type:\"string\"}\n",
        "ExportMADP90s_1_or_0 =  0#@param {type:\"integer\"}\n",
        "\n",
        "years = list(range(StartYear,EndYear))\n",
        "print('Time Period: ', years)\n",
        "\n",
        "def generateStats(outputTable_code):\n",
        "  \n",
        "  \"\"\"\n",
        "  This function generates single images which contain time-aggregated output \n",
        "  statistics including overall mean and shortfall metrics such as MADP90s. \n",
        "  \"\"\"\n",
        "  \n",
        "  # CLIMATE DATA PRE-PROCESSING\n",
        "  # ERA5-Land climate dataset used for worldwide (derived) climate metrics\n",
        "  # https://www.ecmwf.int/en/era5-land\n",
        "  # era5-land HOURLY images in EE catalog\n",
        "  era5Land = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \n",
        "  # print('era5Land',era5Land.limit(50)) # print some data for inspection (debug)\n",
        "  era5Land_proj = era5Land.first().projection() # get ERA5-Land projection & scale for export\n",
        "  era5Land_scale = era5Land_proj.nominalScale()\n",
        "  \n",
        "  # setup the image collection timeseries to chart\n",
        "  # unravel and concatenate all the image stages into a single image collection\n",
        "  \n",
        "  def unravel(i): # function to \"unravel\" image bands into an image collection\n",
        "    def setDate(bandName): # loop over band names in image and return a LIST of ... \n",
        "      dateCode = ee.Date.parse( # ... images, one for each band\n",
        "          format='yyyyMMddHH',\n",
        "          date=ee.String(ee.String(bandName).split('_').get(0)).slice(1) # get date periods from band name\n",
        "      )\n",
        "      return i.select([bandName]).rename('O').set('system:time_start',dateCode)\n",
        "    i = ee.Image(i)\n",
        "    return i.bandNames().map(setDate) # returns a LIST of images\n",
        "\n",
        "  yearCode_list = ee.List(sum([[ # each image units in [L/hr]\n",
        "      unravel(ee.Image(ee_username + '/O_hourly_' + outputTable_code + '_' + str(y)+'a')),\n",
        "      unravel(ee.Image(ee_username + '/O_hourly_' + outputTable_code + '_' + str(y)+'b')),\n",
        "      unravel(ee.Image(ee_username + '/O_hourly_' + outputTable_code + '_' + str(y)+'c')),\n",
        "      unravel(ee.Image(ee_username + '/O_hourly_' + outputTable_code + '_' + str(y)+'d'))              \n",
        "  ] for y in years], [])).flatten()\n",
        "\n",
        "  outputTimeseries = ee.ImageCollection(yearCode_list)\n",
        "\n",
        "  Od_overallMean = outputTimeseries.mean().multiply(24).rename('Od') # hourly output x 24 = mean daily output [L/day]\n",
        "  \n",
        "  # export overall daily mean\n",
        "  task = ee.batch.Export.image.toAsset(\n",
        "    image=Od_overallMean,\n",
        "    region=worldGeo,\n",
        "    description='Od_overallMean_' + outputTable_code + SuffixName_optional,\n",
        "    assetId=ee_username + '/Od_overallMean_' + outputTable_code + SuffixName_optional,\n",
        "    scale=era5Land_scale.getInfo(),\n",
        "    maxPixels=1e10,\n",
        "    maxWorkers=2000\n",
        "  )\n",
        "  task.start()\n",
        "  print('Exporting Od_overallMean_' + outputTable_code + SuffixName_optional)\n",
        "\n",
        "  ## run the moving average function over the timeseries using DAILY averages\n",
        "\n",
        "  # start and end dates over which to calculate aggregate statistics\n",
        "  startDate = ee.Date(str(StartYear) + '-01-01')\n",
        "  endDate = ee.Date(str(EndYear) + '-01-01')\n",
        "\n",
        "  # resample values over time by daily aggregations\n",
        "  # Number of years, in DAYS_PER_RANGE-day increments.\n",
        "  DAYS_PER_RANGE = 1\n",
        "  # DateRangeCollection, which contains the ranges we're interested in.\n",
        "  drc = ee.call('BetterDateRangeCollection',\n",
        "    startDate,\n",
        "    endDate, \n",
        "    DAYS_PER_RANGE, \n",
        "    'day',\n",
        "    True)\n",
        "  # This filter will join images with the date range that contains their start time.\n",
        "  filter = ee.Filter.dateRangeContains('date_range', None, 'system:time_start')\n",
        "  # Save all of the matching values under \"matches\".\n",
        "  join = ee.Join.saveAll('matches')\n",
        "  # Do the join.\n",
        "  joinedResult = join.apply(drc, outputTimeseries, filter)\n",
        "  # print('joinedResult',joinedResult)\n",
        "  \n",
        "  # Map over the functions, and add the mean of the matches as \"meanForRange\".\n",
        "  joinedResult = joinedResult.map(\n",
        "    lambda e: e.set('meanForRange', ee.ImageCollection.fromImages(e.get('matches')).mean())\n",
        "  )\n",
        "  # print('joinedResult',joinedResult)\n",
        "\n",
        "  # roll resampled images into new image collection\n",
        "  outputDaily = ee.ImageCollection(joinedResult.map(\n",
        "      lambda f: ee.Image(f.get('meanForRange')).set(\n",
        "        'system:time_start',\n",
        "        ee.Date.parse('YYYYMMdd',f.get('system:index')).millis()\n",
        "      )\n",
        "  ))\n",
        "  # print('outputDaily',outputDaily.getInfo())\n",
        "\n",
        "  outputDaily_p90 = ee.ImageCollection( # collate rolling periods into new image collection of rolling average values\n",
        "      outputDaily.toList(outputDaily.size())).reduce(\n",
        "        ee.Reducer.percentile( # reduce image collection by percentile\n",
        "          [10] # 100% - 90% = 10%\n",
        "        )).multiply(24).rename('Od')\n",
        "\n",
        "  task = ee.batch.Export.image.toAsset(\n",
        "    image=outputDaily_p90,\n",
        "    region=worldGeo,\n",
        "    description='Od_DailyP90_' + outputTable_code + SuffixName_optional,\n",
        "    assetId=ee_username + '/Od_DailyP90_' + outputTable_code + SuffixName_optional,\n",
        "    scale=era5Land_scale.getInfo(),\n",
        "    maxPixels=1e10,\n",
        "    maxWorkers=2000\n",
        "  )\n",
        "  if ExportMADP90s_1_or_0 == 1:\n",
        "    task.start()\n",
        "    print('Exporting Od_DailyP90_' + outputTable_code + SuffixName_optional)\n",
        "\n",
        "  def rollingStats(period): # run rolling stat function for each rolling period scenerio\n",
        "\n",
        "    # collect neighboring time periods into a join\n",
        "    timeFilter = ee.Filter.maxDifference(\n",
        "      difference=float(period)/2 * 24 * 60 * 60 * 1000, # mid-centered window\n",
        "      leftField='system:time_start', \n",
        "      rightField='system:time_start'\n",
        "    )\n",
        "    rollingPeriod_join = ee.ImageCollection(ee.Join.saveAll('images').apply(\n",
        "      primary=outputDaily, # apply the join on itself to collect images\n",
        "      secondary=outputDaily, \n",
        "      condition=timeFilter\n",
        "    ))\n",
        "    def rollingPeriod_mean(i): # get the mean across each collected periods\n",
        "      i = ee.Image(i) # collected images stored in \"images\" property of each timestep image\n",
        "      return ee.ImageCollection.fromImages(i.get('images')).mean()\n",
        "    outputDaily_rollingMean = rollingPeriod_join.filterDate(\n",
        "        startDate.advance(float(period)/2,'days'),\n",
        "        endDate.advance(float(period)/-2,'days')\n",
        "    ).map(rollingPeriod_mean,True)\n",
        "\n",
        "    Od_p90_rolling = ee.ImageCollection( # collate rolling periods into new image collection of rolling average values\n",
        "      outputDaily_rollingMean.toList(outputDaily_rollingMean.size())).reduce(\n",
        "        ee.Reducer.percentile( # reduce image collection by percentile\n",
        "          [10] # 100% - 90% = 10%\n",
        "        )).multiply(24).rename('Od') # hourly output x 24 = mean daily output [L/day]\n",
        "\n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "      image=Od_p90_rolling,\n",
        "      region=worldGeo,\n",
        "      description='Od_MADP90_'+ period + 'day_' + outputTable_code + SuffixName_optional,\n",
        "      assetId=ee_username + '/Od_MADP90_'+ period + 'day_' + outputTable_code + SuffixName_optional,\n",
        "      scale=era5Land_scale.getInfo(),\n",
        "      maxPixels=1e10,\n",
        "      maxWorkers=2000\n",
        "    )\n",
        "    if ExportMADP90s_1_or_0 == 1:\n",
        "      task.start()\n",
        "      print('Exporting Od_MADP90_' + period + 'day_' + outputTable_code + SuffixName_optional)\n",
        "  \n",
        "  rollingPeriods = [\n",
        "                    '007',\n",
        "                    '030',\n",
        "                    # '060',\n",
        "                    '090',\n",
        "                    # '180',\n",
        "                    ] # define custom rolling periods over which to calc MADP90 [days]\n",
        "        \n",
        "  for period in rollingPeriods: # execute the calculations & export\n",
        "    # print(period)\n",
        "    rollingStats(period)\n",
        "\n",
        "generateStats(OutputTableCode) # run stats function\n",
        "\n",
        "print('Complete! Go to next step.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqPmbM1hPR2Q"
      },
      "source": [
        "Wait until these statistics are completed processing. Track them in the task manager: https://code.earthengine.google.com/\n",
        "\n",
        "When they are finished.... [Go here to see maps](https://code.earthengine.google.com/fac0cc72b2ac2e431424cbf45b2852cf)"
      ]
    }
  ]
}
