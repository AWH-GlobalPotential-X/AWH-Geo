{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AWH-Geo",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AWH-GlobalPotential-X/AWH-Geo/blob/main/AWH_Geo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WVlEskqN7cz"
      },
      "source": [
        "Welcome to AWH-Geo\n",
        "\n",
        "This tool requires a Google Drive and Earth Engine Account\n",
        "\n",
        "[Start here](https://docs.google.com/spreadsheets/d/1Lltb02fwazGZIKwdhy42nm3jtW5SHUrQVyiIR6Y5BOs/edit?usp=sharing) to create a new Output Table from the template:\n",
        " 1. Right-click on \"OutputTable_TEMPLATE\" file > Make a Copy to your own Drive folder\n",
        " 2. Rename the new file \"OuputTable_CODENAME\" with CODENAME (max 83 characters!) as a unique output table code. If including a date in the code, use the YYYYMMDD date format.\n",
        " 3. Enter in the output values in L/hr to each cell in each of the 10%-interval rH bins... interpolate in Sheets as necessary.\n",
        "\n",
        "Then, click \"Connect\" at the top right of this notebook.\n",
        "\n",
        "Then run each of the code blocks below, following instructions. For \"OutputTableCode\" inputs, use the CODENAME you created in Sheets.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stHr1at7Vz4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "0221966e-1b96-4c7e-b0eb-cc6dbb50c145"
      },
      "source": [
        "#@title STEP 1: Basic setup and earthengine access. Enter your Earth Engine username:\n",
        "\n",
        "ee_username = \"jacksonlord_personal\" #@param {type:\"string\"}\n",
        "\n",
        "print('Welcome to AWH-Geo')\n",
        "\n",
        "# import, authenticate, then initialize EarthEngine module ee\n",
        "# https://developers.google.com/earth-engine/python_install#package-import\n",
        "import ee \n",
        "print('Make sure the EE version is v0.1.215 or greater...')\n",
        "print('Current EE version = v' + ee.__version__)\n",
        "print('')\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "worldGeo = ee.Geometry.Polygon( # Created for some masking and geo calcs\n",
        "  coords=[[-180,-90],[-180,0],[-180,90],[-30,90],[90,90],[180,90],\n",
        "          [180,0],[180,-90],[30,-90],[-90,-90],[-180,-90]],\n",
        "  geodesic=False,\n",
        "  proj='EPSG:4326'\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to AWH-Geo\n",
            "Make sure the EE version is v0.1.215 or greater...\n",
            "Current EE version = v0.1.238\n",
            "\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=DjM0gWZz3eGlpzwtnpkXWLj_QdBxy1VzJiFJ47Dg-xA&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AY0e-g5AYBlqxB8QTtUan-7dP5_Q8aotYWsElAZ2Oa5w1gH7ulrM87_Lazs\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdm_p_0kXJ4k",
        "cellView": "form"
      },
      "source": [
        "#@title STEP 2:  Test Earth Engine connection (see Mt Everest elev and a green map)\n",
        "# Print the elevation of Mount Everest.\n",
        "dem = ee.Image('USGS/SRTMGL1_003')\n",
        "xy = ee.Geometry.Point([86.9250, 27.9881])\n",
        "elev = dem.sample(xy, 30).first().get('elevation').getInfo()\n",
        "print('Mount Everest elevation (m):', elev)\n",
        "\n",
        "# Access H2E assets\n",
        "from IPython.display import Image\n",
        "Image(url=jmpGeofabric_image.getThumbUrl({'min': 0, 'max': 1, 'dimensions': 512,\n",
        "                'palette': ['006633', 'E5FFCC', '662A00', 'D8D8D8', 'F5F5F5']}))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HExr-p1zf2zm",
        "cellView": "form"
      },
      "source": [
        "#@title STEP 3: Set up access to Google Sheets (follow instructions)\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# gspread is module to access Google Sheets through python\n",
        "# https://gspread.readthedocs.io/en/latest/index.html\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default()) # get credentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k6X9TzPg3gl",
        "cellView": "form"
      },
      "source": [
        "#@title STEP 4: Export timeseries for given OutputTable: enter CODENAME (without \"OutputTable_\" prefix) below\n",
        "\n",
        "def timeseriesExport(outputTable_code):\n",
        "  \n",
        "  \"\"\"\n",
        "  This script runs the output table value over the climate variables using the \n",
        "  nearest lookup values, worldwide, every three hours during the five-year \n",
        "  period 2013 to 2018. It then resamples the temporal interval by averaging the \n",
        "  hourly output over semi-week periods. It then converts the resulting image \n",
        "  collection into a single image with several bands, each of which representing \n",
        "  one (hourly or semi-week) interval. Finally, it exports this image over \n",
        "  6-month tranches and saves each as an EE Image Assets with appropriate names \n",
        "  corresponding to the tranche's time period. \n",
        "  \"\"\"\n",
        "  \n",
        "  # print the output table code from user input for confirmation\n",
        "  print('outputTable code:', outputTable_code)\n",
        "\n",
        "  # CLIMATE DATA PRE-PROCESSING\n",
        "  # ERA5-Land climate dataset used for worldwide (derived) climate metrics\n",
        "  # https://www.ecmwf.int/en/era5-land\n",
        "  # era5-land HOURLY images in EE catalog\n",
        "  era5Land = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \n",
        "  # print('era5Land',era5Land.limit(50)) # print some data for inspection (debug)\n",
        "  era5Land_proj = era5Land.first().projection() # get ERA5-Land projection & scale for export\n",
        "  era5Land_scale = era5Land_proj.nominalScale()\n",
        "  print('era5Land_scale (should be ~11132):',era5Land_scale.getInfo())\n",
        "  era5Land_filtered = era5Land.filterDate( # ERA5-Land climate data\n",
        "    '2012-12-31','2018-01-01').select( # filter by date\n",
        "        # filter by ERA5-Land image collection bands                              \n",
        "        [\n",
        "         'dewpoint_temperature_2m', # K (https://apps.ecmwf.int/codes/grib/param-db?id=168)\n",
        "         'surface_solar_radiation_downwards', # J/m^2 (Accumulated value. Divide by 3600 to get W/m^2 over hourly interval https://apps.ecmwf.int/codes/grib/param-db?id=176)\n",
        "         'temperature_2m' # K\n",
        "         ]) \n",
        "  # print('era5Land_filtered',era5Land_filtered.limit(50))\n",
        "\n",
        "  print('Wait... retrieving data from sheets takes a couple minutes')\n",
        "\n",
        "  # COLLECT OUTPUT TABLE DATA FROM SHEETS INTO PYTHON ARRAYS\n",
        "  # gspread function which will look in list of gSheets accessible to user\n",
        "  # in Earth Engine, an array is a list of lists.\n",
        "  # loop through worksheet tabs and build a list of lists of lists (3 dimensional)\n",
        "  # to organize output values [L/hr] by the 3 physical variables in the following\n",
        "  # order: by temperature (first nesting leve), ghi (second nesting level), then\n",
        "  # rH (third nesting level).\n",
        "  spreadsheet = gc.open('OutputTable_' + outputTable_code) \n",
        "  outputArray = list() # create empty array\n",
        "  rH_labels = ['rH0','rH10','rH20','rH30','rH40','rH50', # worksheet tab names\n",
        "               'rH60','rH70','rH80','rH90','rH100']\n",
        "  for rH in rH_labels: # loop to create 3-D array (list of lists of lists)\n",
        "    rH_interval_array = list() \n",
        "    worksheet = spreadsheet.worksheet(rH)\n",
        "    for x in list(range(7,22)): # relevant ranges in output table sheet\n",
        "      rH_interval_array.append([float(y) for y in worksheet.row_values(x)])\n",
        "    outputArray.append(rH_interval_array)\n",
        "  # print('Output Table values:', outputArray) # for debugging\n",
        "  # create an array image in EE (each pixel is a multi-dimensional matrix)\n",
        "  outputImage_arrays = ee.Image(ee.Array(outputArray)) # values are in [L/hr]\n",
        "\n",
        "  def processTimeseries(i): # core processing algorithm with lookups to outputTable\n",
        "\n",
        "    \"\"\"\n",
        "    This is the core AWH-Geo algorithm to convert image-based input climate data \n",
        "    into an image of AWG device output [L/time] based on a given output lookup table.\n",
        "    It runs across the ERA5-Land image collection timeseries and runs the lookup table \n",
        "    on each pixel of each image representing each hourly climate timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    i = ee.Image(i) # cast as image\n",
        "    i = i.updateMask(i.select('temperature_2m').mask()) # ensure mask is applied to all bands\n",
        "    timestamp_millis = ee.Date(i.get('system:time_start'))\n",
        "    i_previous = ee.Image(era5Land_filtered.filterDate(\n",
        "        timestamp_millis.advance(-1,'hour')).first())\n",
        "    rh = ee.Image().expression( # relative humidity calculation [%]\n",
        "    # from http://bmcnoldy.rsmas.miami.edu/Humidity.html\n",
        "      '100 * (e**((17.625 * Td) / (To + Td)) / e**((17.625 * T) / (To + T)))', {\n",
        "        'e': 2.718281828459045, # Euler's constant\n",
        "        'T': i.select('temperature_2m').subtract(273.15), # temperature K converted to Celsius [°C]\n",
        "        'Td': i.select('dewpoint_temperature_2m').subtract(273.15), # dewpoint temperature K converted to Celsius [°C]\n",
        "        'To': 243.04 # reference temperature [K]\n",
        "      }).rename('rh')\n",
        "    ghi = ee.Image(ee.Algorithms.If( # because this parameter in ERA5 is cumulative in J/m^2...\n",
        "        condition=ee.Number(timestamp_millis.get('hour')).eq(1), # ...from last obseration...\n",
        "        trueCase=i.select('surface_solar_radiation_downwards'), # ...current value must be...\n",
        "        falseCase=i.select('surface_solar_radiation_downwards').subtract( # ...subtracted from last...\n",
        "            i_previous.select('surface_solar_radiation_downwards')) # ... then divided by seconds\n",
        "      )).divide(3600).clamp(0,1200).rename('ghi') # solar global horizontal irradiance [W/m^2]\n",
        "    temp = i.select('temperature_2m'\n",
        "                    ).subtract(273.15).rename('temp') # temperature K converted to Celsius [°C]\n",
        "    rhClamp = rh.clamp(0.1,100) # relative humdity clamped to output table range [%]\n",
        "    ghiClamp = ghi.clamp(0.1,1200) # global horizontal irradiance clamped to range [W/m^2]\n",
        "    tempClamp = temp.clamp(10,45) # temperature clamped to output table range [°C]\n",
        "    # convert climate variables to lookup integers\n",
        "    rhLookup = rhClamp.divide(10).round().int().rename('rhLookup') # rH lookup interval\n",
        "    tempLookup = tempClamp.subtract(10).divide(2.5\n",
        "                    ).round().int().rename('tempLookup') # temp lookup interval\n",
        "    ghiLookup = ghiClamp.divide(100\n",
        "                                ).add(1).round().int().rename('ghiLookup') # ghi lookup interval\n",
        "    # combine lookup values in a 3-band image\n",
        "    xyzLookup = ee.Image(rhLookup).addBands(tempLookup).addBands(ghiLookup) \n",
        "    # lookup values in 3D array for each pixel to return AWG output from table [L/hr]\n",
        "    output = outputImage_arrays.arrayGet(xyzLookup) \n",
        "    # nightMask = ghi.gt(2.5) # mask pixels which have no incident sunlight\n",
        "\n",
        "    return ee.Image(output.rename('O').addBands( # return image of output labeled \"O\" [L/hr]\n",
        "      rh).addBands(ghi).addBands(temp).setMulti({ # add physical variables as bands\n",
        "        'system:time_start': timestamp_millis # set time as property\n",
        "      })).updateMask(1) # close partial masks at continental edges\n",
        "\n",
        "  def outputHourly_export(timeStart, timeEnd, name):\n",
        "\n",
        "    \"\"\"\n",
        "    Run the lookup processing function (from above) across the entire climate \n",
        "    timeseries at the finest temporal interval (1 hr for ERA5-Land). Convert the \n",
        "    resulting image collection as a single image with a band for each timestep \n",
        "    to allow for export as an Earth Engine asset (you cannot export/save image\n",
        "    collections as assets).\n",
        "    \"\"\"\n",
        "\n",
        "    # filter ERA5-Land climate data by time\n",
        "    era5Land_filtered_section = era5Land_filtered.filterDate(timeStart, timeEnd)\n",
        "\n",
        "    # print('era5Land_filtered_section',era5Land_filtered_section.limit(1).getInfo())\n",
        "\n",
        "    outputHourly = era5Land_filtered_section.map(processTimeseries) \n",
        "    # outputHourly_toBands_pre = outputHourly.select(['ghi']).toBands()\n",
        "    outputHourly_toBands_pre = outputHourly.select(['O']).toBands()\n",
        "    outputHourly_toBands = outputHourly_toBands_pre.select(\n",
        "      # input climate variables as multiband image with each band representing timestep\n",
        "      outputHourly_toBands_pre.bandNames(), \n",
        "      # rename bands by timestamp\n",
        "      outputHourly_toBands_pre.bandNames().map(\n",
        "        lambda name: ee.String('H').cat( # \"H\" for hourly\n",
        "          ee.String(name).replace('T','')\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "\n",
        "    # notify user of export\n",
        "    print('Exporting outputHourly year:', name)\n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "      image=ee.Image(outputHourly_toBands),\n",
        "      region=worldGeo,\n",
        "      description='/O_hourly_' + outputTable_code + '_' + name,\n",
        "      assetId='users/' + ee_username + '/O_hourly_' + outputTable_code + '_' + name,\n",
        "      scale=era5Land_scale.getInfo(),\n",
        "      crs='EPSG:4326',\n",
        "      maxPixels=1e10,\n",
        "      maxWorkers=2000\n",
        "    )\n",
        "    task.start()\n",
        "  \n",
        "  # run timeseries export on entire hourly ERA5-Land for each yearly tranche\n",
        "  outputHourly_export('2013-01-01','2013-04-01','2013a')\n",
        "  outputHourly_export('2013-04-01','2013-07-01','2013b')\n",
        "  outputHourly_export('2013-07-01','2013-10-01','2013c')\n",
        "  outputHourly_export('2013-10-01','2014-01-01','2013d')\n",
        "\n",
        "  outputHourly_export('2014-01-01','2014-04-01','2014a')\n",
        "  outputHourly_export('2014-04-01','2014-07-01','2014b')\n",
        "  outputHourly_export('2014-07-01','2014-10-01','2014c')\n",
        "  outputHourly_export('2014-10-01','2015-01-01','2014d')\n",
        "\n",
        "  outputHourly_export('2015-01-01','2015-04-01','2015a')\n",
        "  outputHourly_export('2015-04-01','2015-07-01','2015b')\n",
        "  outputHourly_export('2015-07-01','2015-10-01','2015c')\n",
        "  outputHourly_export('2015-10-01','2016-01-01','2015d')\n",
        "\n",
        "  outputHourly_export('2016-01-01','2016-04-01','2016a')\n",
        "  outputHourly_export('2016-04-01','2016-07-01','2016b')\n",
        "  outputHourly_export('2016-07-01','2016-10-01','2016c')\n",
        "  outputHourly_export('2016-10-01','2017-01-01','2016d')\n",
        "\n",
        "  outputHourly_export('2017-01-01','2017-04-01','2017a')\n",
        "  outputHourly_export('2017-04-01','2017-07-01','2017b')\n",
        "  outputHourly_export('2017-07-01','2017-10-01','2017c')\n",
        "  outputHourly_export('2017-10-01','2018-01-01','2017d')\n",
        "\n",
        "  def outputWeekly_export(timeStart, timeEnd, name):\n",
        "\n",
        "    era5Land_filtered_section = era5Land_filtered.filterDate(timeStart, timeEnd) # filter ERA5-Land climate data by time\n",
        "    \n",
        "    outputHourly = era5Land_filtered_section.map(processTimeseries)\n",
        "    \n",
        "    # resample values over time by 2-week aggregations\n",
        "    # Define a time interval\n",
        "    start = ee.Date(timeStart)\n",
        "    end = ee.Date(timeEnd)\n",
        "    # Number of years, in DAYS_PER_RANGE-day increments.\n",
        "    DAYS_PER_RANGE = 14\n",
        "    # DateRangeCollection, which contains the ranges we're interested in.\n",
        "    drc = ee.call(\"BetterDateRangeCollection\",\n",
        "      start,\n",
        "      end, \n",
        "      DAYS_PER_RANGE, \n",
        "      \"day\",\n",
        "      True)\n",
        "    # This filter will join images with the date range that contains their start time.\n",
        "    filter = ee.Filter.dateRangeContains(\"date_range\", None, \"system:time_start\")\n",
        "    # Save all of the matching values under \"matches\".\n",
        "    join = ee.Join.saveAll(\"matches\")\n",
        "    # Do the join.\n",
        "    joinedResult = join.apply(drc, outputHourly, filter)\n",
        "    # print('joinedResult',joinedResult)\n",
        "    \n",
        "    # Map over the functions, and add the mean of the matches as \"meanForRange\".\n",
        "    joinedResult = joinedResult.map(\n",
        "      lambda e: e.set(\"meanForRange\", ee.ImageCollection.fromImages(e.get(\"matches\")).mean())\n",
        "    )\n",
        "    # print('joinedResult',joinedResult)\n",
        "\n",
        "    # roll resampled images into new image collection\n",
        "    outputWeekly = ee.ImageCollection(joinedResult.map(\n",
        "        lambda f: ee.Image(f.get('meanForRange'))\n",
        "    ))\n",
        "    # print('outputWeekly',outputWeekly.getInfo())\n",
        "\n",
        "    # convert image collection into image with many bands which can be saved as EE asset\n",
        "    outputWeekly_toBands_pre = outputWeekly.toBands()\n",
        "    outputWeekly_toBands = outputWeekly_toBands_pre.select(\n",
        "        outputWeekly_toBands_pre.bandNames(), # input climate variables as multiband image with each band representing timestep\n",
        "        outputWeekly_toBands_pre.bandNames().map(\n",
        "            lambda name: ee.String('W').cat(name)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    print('Exporting outputWeekly year:', name)\n",
        "    \n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "      image=ee.Image(outputWeekly_toBands),\n",
        "      region=worldGeo,\n",
        "      description='O_weekly_' + outputTable_code + '_' + name,\n",
        "      assetId='users/' + ee_username + 'O_weekly_' + outputTable_code + '_' + name,\n",
        "      scale=era5Land_scale.getInfo(),\n",
        "      crs='EPSG:4326',\n",
        "      maxPixels=1e10,\n",
        "      maxWorkers=2000\n",
        "    )\n",
        "    # task.start() # remove comment hash if weekly exports are desired\n",
        "\n",
        "  # run semi-weekly timeseries export on ERA5-Land by year\n",
        "  outputWeekly_export('2013-01-01','2013-04-01','2013a')\n",
        "  outputWeekly_export('2013-04-01','2013-07-01','2013b')\n",
        "  outputWeekly_export('2013-07-01','2013-10-01','2013c')\n",
        "  outputWeekly_export('2013-10-01','2014-01-01','2013d')\n",
        "\n",
        "  outputWeekly_export('2014-01-01','2014-04-01','2014a')\n",
        "  outputWeekly_export('2014-04-01','2014-07-01','2014b')\n",
        "  outputWeekly_export('2014-07-01','2014-10-01','2014c')\n",
        "  outputWeekly_export('2014-10-01','2015-01-01','2014d')\n",
        "\n",
        "  outputWeekly_export('2015-01-01','2015-04-01','2015a')\n",
        "  outputWeekly_export('2015-04-01','2015-07-01','2015b')\n",
        "  outputWeekly_export('2015-07-01','2015-10-01','2015c')\n",
        "  outputWeekly_export('2015-10-01','2016-01-01','2015d')\n",
        "\n",
        "  outputWeekly_export('2016-01-01','2016-04-01','2016a')\n",
        "  outputWeekly_export('2016-04-01','2016-07-01','2016b')\n",
        "  outputWeekly_export('2016-07-01','2016-10-01','2016c')\n",
        "  outputWeekly_export('2016-10-01','2017-01-01','2016d')\n",
        "\n",
        "  outputWeekly_export('2017-01-01','2017-04-01','2017a')\n",
        "  outputWeekly_export('2017-04-01','2017-07-01','2017b')\n",
        "  outputWeekly_export('2017-07-01','2017-10-01','2017c')\n",
        "  outputWeekly_export('2017-10-01','2018-01-01','2017d')\n",
        "\n",
        "OutputTableCode = \"jacksonTest20200410\" #@param {type:\"string\"}\n",
        "timeseriesExport(OutputTableCode)\n",
        "\n",
        "print('Complete! Read instructions below')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7G6VUdE1g5e"
      },
      "source": [
        "# *Before moving on to the next step... Wait until above tasks are complete in the task manager: https://code.earthengine.google.com/*\n",
        "(right pane, tab \"tasks\", click \"refresh\"; the should show up once the script prints \"Exporting...\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptJRgoHbicHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "7dd1ddb9-bf94-426f-c630-ccf6a92c3e81"
      },
      "source": [
        "#@title STEP 5: Re-instate earthengine access (follow instructions)\n",
        "\n",
        "print('Welcome Back to AWH-Geo')\n",
        "print('')\n",
        "\n",
        "# import, authenticate, then initialize EarthEngine module ee\n",
        "# https://developers.google.com/earth-engine/python_install#package-import\n",
        "import ee \n",
        "print('Make sure the EE version is v0.1.215 or greater...')\n",
        "print('Current EE version = v' + ee.__version__)\n",
        "print('')\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "\n",
        "worldGeo = ee.Geometry.Polygon( # Created for some masking and geo calcs\n",
        "  coords=[[-180,-90],[-180,0],[-180,90],[-30,90],[90,90],[180,90],\n",
        "          [180,0],[180,-90],[30,-90],[-90,-90],[-180,-90]],\n",
        "  geodesic=False,\n",
        "  proj='EPSG:4326'\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome Back to AWH-Geo\n",
            "\n",
            "Make sure the EE version is v0.1.215 or greater...\n",
            "Current EE version = v0.1.238\n",
            "\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=MorY5w-XsLGoynRF-QXAVjABIutUYrkLLBXTvNS7PDU&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AY0e-g7-f4mc9RR2bgzca5oaW9ZxqM3109KnKOwIiSvlH-F_dmmRxrZ_ycg\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfApoE9rtB9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "4bd3876e-89d9-4bc9-e872-6fbcf41000eb"
      },
      "source": [
        "#@title STEP 6: Export statistical results for given OutputTable: enter CODENAME (without \"OutputTable_\" prefix) below\n",
        "\n",
        "def generateStats(outputTable_code):\n",
        "  \n",
        "  \"\"\"\n",
        "  This function generates single images which contain time-aggregated output statistics including \n",
        "  overall mean and shortfall metrics such as MADP90s. \n",
        "  \"\"\"\n",
        "  \n",
        "  # CLIMATE DATA PRE-PROCESSING\n",
        "  # ERA5-Land climate dataset used for worldwide (derived) climate metrics\n",
        "  # https://www.ecmwf.int/en/era5-land\n",
        "  # era5-land HOURLY images in EE catalog\n",
        "  era5Land = ee.ImageCollection('ECMWF/ERA5_LAND/HOURLY') \n",
        "  # print('era5Land',era5Land.limit(50)) # print some data for inspection (debug)\n",
        "  era5Land_proj = era5Land.first().projection() # get ERA5-Land projection & scale for export\n",
        "  era5Land_scale = era5Land_proj.nominalScale()\n",
        "  \n",
        "  # setup the image collection timeseries to chart\n",
        "  O_2013a = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2013a') # [L/hr]\n",
        "  O_2013b = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2013b')\n",
        "  O_2013c = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2013c')\n",
        "  O_2013d = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2013d')\n",
        "\n",
        "  O_2014a = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2014a') # [L/hr]\n",
        "  O_2014b = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2014b')\n",
        "  O_2014c = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2014c')\n",
        "  O_2014d = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2014d')\n",
        "  \n",
        "  O_2015a = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2015a') # [L/hr]\n",
        "  O_2015b = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2015b')\n",
        "  O_2015c = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2015c')\n",
        "  O_2015d = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2015d')\n",
        "\n",
        "  O_2016a = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2016a') # [L/hr]\n",
        "  O_2016b = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2016b')\n",
        "  O_2016c = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2016c')\n",
        "  O_2016d = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2016d')\n",
        "\n",
        "  O_2017a = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2017a') # [L/hr]\n",
        "  O_2017b = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2017b')\n",
        "  O_2017c = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2017c')\n",
        "  O_2017d = ee.Image('users/' + ee_username + '/O_hourly_' + outputTable_code + '_2017d')\n",
        "  \n",
        "  def unravel(i): # function to \"unravel\" image bands into an image collection\n",
        "    def setDate(bandName): # loop over band names in image\n",
        "      dateCode = ee.Date.parse(\n",
        "          format='yyyyMMddHH',\n",
        "          date=ee.String(ee.String(bandName).split('_').get(0)).slice(1) # get date periods from band name\n",
        "      )\n",
        "      return i.select([bandName]).rename('O').set('system:time_start',dateCode)\n",
        "    i = ee.Image(i)\n",
        "    return i.bandNames().map(setDate)\n",
        "  # print('testRavel',unravel(O_2013))\n",
        "  \n",
        "  # unravel and concatenate all the image stages into a single image collection\n",
        "  outputTimeseries = ee.ImageCollection(ee.List(\n",
        "      \n",
        "    unravel(O_2013a)).cat(\n",
        "    unravel(O_2013a)).cat(\n",
        "    unravel(O_2013a)).cat(\n",
        "    unravel(O_2013a)).cat(\n",
        "\n",
        "    unravel(O_2014a)).cat(\n",
        "    unravel(O_2014a)).cat(\n",
        "    unravel(O_2014a)).cat(\n",
        "    unravel(O_2014a)).cat(\n",
        "\n",
        "    unravel(O_2015a)).cat(\n",
        "    unravel(O_2015a)).cat(\n",
        "    unravel(O_2015a)).cat(\n",
        "    unravel(O_2015a)).cat(\n",
        "\n",
        "    unravel(O_2016a)).cat(\n",
        "    unravel(O_2016a)).cat(\n",
        "    unravel(O_2016a)).cat(\n",
        "    unravel(O_2016a)).cat(\n",
        "\n",
        "    unravel(O_2017a)).cat(\n",
        "    unravel(O_2017a)).cat(\n",
        "    unravel(O_2017a)).cat(\n",
        "    unravel(O_2017a)))\n",
        "  \n",
        "  # print('outputTimeseries',outputTimeseries.limit(50))\n",
        "\n",
        "  Od_overallMean = outputTimeseries.mean().multiply(24).rename('Od') # hourly output x 24 = mean daily output [L/day]\n",
        "  \n",
        "  # export overall daily mean\n",
        "  task = ee.batch.Export.image.toAsset(\n",
        "    image=Od_overallMean,\n",
        "    region=worldGeo,\n",
        "    description='Od_overallMean_' + outputTable_code,\n",
        "    assetId='users/' + ee_username + '/Od_overallMean_' + outputTable_code,\n",
        "    scale=era5Land_scale.getInfo(),\n",
        "    crs='EPSG:4326',\n",
        "    maxPixels=1e10,\n",
        "    maxWorkers=2000\n",
        "  )\n",
        "  task.start()\n",
        "  print('Exporting Od_overallMean_' + outputTable_code)\n",
        "\n",
        "  ## run the moving average function over the timeseries using DAILY averages\n",
        "\n",
        "  # start and end dates over which to calculate aggregate statistics\n",
        "  startDate = ee.Date('2013-01-01')\n",
        "  endDate = ee.Date('2018-01-01')\n",
        "\n",
        "  # resample values over time by daily aggregations\n",
        "  # Number of years, in DAYS_PER_RANGE-day increments.\n",
        "  DAYS_PER_RANGE = 1\n",
        "  # DateRangeCollection, which contains the ranges we're interested in.\n",
        "  drc = ee.call('BetterDateRangeCollection',\n",
        "    startDate,\n",
        "    endDate, \n",
        "    DAYS_PER_RANGE, \n",
        "    'day',\n",
        "    True)\n",
        "  # This filter will join images with the date range that contains their start time.\n",
        "  filter = ee.Filter.dateRangeContains('date_range', None, 'system:time_start')\n",
        "  # Save all of the matching values under \"matches\".\n",
        "  join = ee.Join.saveAll('matches')\n",
        "  # Do the join.\n",
        "  joinedResult = join.apply(drc, outputTimeseries, filter)\n",
        "  # print('joinedResult',joinedResult)\n",
        "  \n",
        "  # Map over the functions, and add the mean of the matches as \"meanForRange\".\n",
        "  joinedResult = joinedResult.map(\n",
        "    lambda e: e.set('meanForRange', ee.ImageCollection.fromImages(e.get('matches')).mean())\n",
        "  )\n",
        "  # print('joinedResult',joinedResult)\n",
        "\n",
        "  # roll resampled images into new image collection\n",
        "  outputDaily = ee.ImageCollection(joinedResult.map(\n",
        "      lambda f: ee.Image(f.get('meanForRange')).set(\n",
        "        'system:time_start',\n",
        "        ee.Date.parse('YYYYMMdd',f.get('system:index')).millis()\n",
        "      )\n",
        "  ))\n",
        "  # print('outputDaily',outputDaily.getInfo())\n",
        "\n",
        "  outputDaily_p90 = ee.ImageCollection( # collate rolling periods into new image collection of rolling average values\n",
        "      outputDaily.toList(outputDaily.size())).reduce(\n",
        "        ee.Reducer.percentile( # reduce image collection by percentile\n",
        "          [10] # 100% - 90% = 10%\n",
        "        )).multiply(24).rename('Od')\n",
        "\n",
        "  task = ee.batch.Export.image.toAsset(\n",
        "    image=outputDaily_p90,\n",
        "    region=worldGeo,\n",
        "    description='Od_DailyP90_' + outputTable_code,\n",
        "    assetId='users/' + ee_username + '/Od_DailyP90_' + outputTable_code,\n",
        "    scale=era5Land_scale.getInfo(),\n",
        "    crs='EPSG:4326',\n",
        "    maxPixels=1e10,\n",
        "    maxWorkers=2000\n",
        "  )\n",
        "  task.start()\n",
        "  print('Exporting Od_DailyP90_' + outputTable_code)\n",
        "\n",
        "  def rollingStats(period): # run rolling stat function for each rolling period scenerio\n",
        "\n",
        "    # collect neighboring time periods into a join\n",
        "    timeFilter = ee.Filter.maxDifference(\n",
        "      difference=float(period)/2 * 24 * 60 * 60 * 1000, # mid-centered window\n",
        "      leftField='system:time_start', \n",
        "      rightField='system:time_start'\n",
        "    )\n",
        "    rollingPeriod_join = ee.ImageCollection(ee.Join.saveAll('images').apply(\n",
        "      primary=outputDaily, # apply the join on itself to collect images\n",
        "      secondary=outputDaily, \n",
        "      condition=timeFilter\n",
        "    ))\n",
        "    def rollingPeriod_mean(i): # get the mean across each collected periods\n",
        "      i = ee.Image(i) # collected images stored in \"images\" property of each timestep image\n",
        "      return ee.ImageCollection.fromImages(i.get('images')).mean()\n",
        "    outputDaily_rollingMean = rollingPeriod_join.filterDate(\n",
        "        startDate.advance(float(period)/2,'days'),\n",
        "        endDate.advance(float(period)/-2,'days')\n",
        "    ).map(rollingPeriod_mean,True)\n",
        "\n",
        "    Od_p90_rolling = ee.ImageCollection( # collate rolling periods into new image collection of rolling average values\n",
        "      outputDaily_rollingMean.toList(outputDaily_rollingMean.size())).reduce(\n",
        "        ee.Reducer.percentile( # reduce image collection by percentile\n",
        "          [10] # 100% - 90% = 10%\n",
        "        )).multiply(24).rename('Od') # hourly output x 24 = mean daily output [L/day]\n",
        "\n",
        "    task = ee.batch.Export.image.toAsset(\n",
        "      image=Od_p90_rolling,\n",
        "      region=worldGeo,\n",
        "      description='Od_MADP90_'+ period + 'day_' + outputTable_code,\n",
        "      assetId='users/' + ee_username + '/Od_MADP90_'+ period + 'day_' + outputTable_code,\n",
        "      scale=era5Land_scale.getInfo(),\n",
        "      crs='EPSG:4326',\n",
        "      maxPixels=1e10,\n",
        "      maxWorkers=2000\n",
        "    )\n",
        "    task.start()\n",
        "    print('Exporting Od_MADP90_' + period + 'day_' + outputTable_code)\n",
        "  \n",
        "  rollingPeriods = [\n",
        "                    '007',\n",
        "                    '030',\n",
        "                    '060',\n",
        "                    '090',\n",
        "                    '180',\n",
        "                    ] # define custom rolling periods over which to calc MADP90 [days]\n",
        "        \n",
        "  for period in rollingPeriods: # execute the calculations & export\n",
        "    # print(period)\n",
        "    rollingStats(period)\n",
        "\n",
        "OutputTableCode = \"jacksonTest20200410\" #@param {type:\"string\"}\n",
        "generateStats(OutputTableCode) # run stats function\n",
        "\n",
        "print('Complete! Go to next step.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EEException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/image:export?alt=json returned \"Image.load: Image asset 'users/jacksonlord_personal/O_hourly_jacksonTest20200410_2017a' not found.\">",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b22611eec42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0mOutputTableCode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"jacksonTest20200410\"\u001b[0m \u001b[0;31m#@param {type:\"string\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m \u001b[0mgenerateStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutputTableCode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run stats function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Complete! Go to next step.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b22611eec42d>\u001b[0m in \u001b[0;36mgenerateStats\u001b[0;34m(outputTable_code)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mmaxWorkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   )\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exporting Od_overallMean_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputTable_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ee/batch.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPORT_IMAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexportImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPORT_MAP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexportMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ee/data.py\u001b[0m in \u001b[0;36mexportImage\u001b[0;34m(request_id, params)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     return _prepare_and_run_export(\n\u001b[1;32m   1353\u001b[0m         \u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1354\u001b[0;31m         _get_cloud_api_resource().projects().image().export)\n\u001b[0m\u001b[1;32m   1355\u001b[0m   \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'EXPORT_IMAGE'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstartProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_prepare_and_run_export\u001b[0;34m(request_id, params, export_endpoint)\u001b[0m\n\u001b[1;32m   1480\u001b[0m   return _execute_cloud_call(\n\u001b[1;32m   1481\u001b[0m       \u001b[0mexport_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m       num_retries=num_retries)\n\u001b[0m\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEEException\u001b[0m: Image.load: Image asset 'users/jacksonlord_personal/O_hourly_jacksonTest20200410_2017a' not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C84oMMA4enyZ"
      },
      "source": [
        "  # import WHO JMP geo fabric and an ISO country lookup table to report water-starved percentages\n",
        "  jmpGeoFabric = ee.FeatureCollection('users/jacksonlord_personal/h2e/jmpGeoFabric')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}